Collecting workspace informationPer integrare un secondo LLM per la valutazione, puoi seguire questi passaggi:

1.  **Modifica `generate_notes` in app.py:** Dopo aver generato il contenuto formattato (`formatted_content`) per un argomento, ma prima di salvarlo nel database o aggiungerlo a `generated_notes`, inserisci una chiamata al client LLM per la valutazione.
2.  **Crea un Prompt di Valutazione:** Definisci un prompt specifico per il secondo LLM (o per lo stesso LLM con un ruolo diverso) che chieda di valutare il `formatted_content` basandosi su criteri come chiarezza, pertinenza, completezza, ecc., e di restituire un punteggio o un feedback testuale, preferibilmente in formato JSON.
3.  **Chiama l'LLM:** Usa l'istanza esistente `gemini_client` (o un nuovo client se usi un LLM diverso) per inviare il prompt di valutazione insieme al `formatted_content`.
4.  **Elabora la Risposta:** Analizza la risposta dell'LLM di valutazione (es. estrai il punteggio JSON).
5.  **Utilizza il Risultato:** Puoi registrare il risultato della valutazione (usando `logger.info`), salvarlo nel database (richiede modifiche al modello `Note`), o mostrarlo all'utente (richiede modifiche al template `templates/results.html`).

Ecco un esempio di come potresti modificare la funzione `generate_notes` in app.py per includere un passaggio di valutazione e registrarne il risultato:

```python
# ... (altre importazioni) ...
import json # Aggiungi import json

# ... (codice esistente) ...

@app.route('/generate_notes', methods=['POST']) # Cambiato nome route per chiarezza
def generate_notes():
    start_time = datetime.now() # Per logging del tempo totale
    try:
        # ... (codice esistente per ottenere session_id, format, topics, etc.) ...

        # --- INIZIO CICLO SU TUTTI GLI ARGOMENTI ---
        for topic_id, topic_data in topics_dict.items():

            logger.info(f"Processando argomento: {topic_data['name']} ({topic_id})")

            # Blocco try/except per singolo argomento, per permettere al ciclo di continuare
            try:
                # ... (codice esistente per controllare note DB, generare topic_info, enhanced_info, image_content) ...

                # --- Combinazione e Formattazione ---
                combined_content = enhanced_info
                if image_content:
                    combined_content += image_content

                formatted_content = format_converter.convert(
                    topic_data['name'],
                    combined_content,
                    output_format
                )

                # --- INIZIO VALUTAZIONE LLM ---
                try:
                    evaluation_prompt = f"""
                    You are an expert evaluator of educational content. Please evaluate the following generated note content for the topic "{topic_data['name']}" based on clarity, relevance to the topic name, and overall quality. Provide a numerical score from 1 (poor) to 10 (excellent) and a brief justification (1-2 sentences).

                    Format your response as a JSON object:
                    {{
                      "score": <integer_score>,
                      "justification": "<brief_justification>"
                    }}

                    Note Content to Evaluate:
                    ---
                    {formatted_content[:4000]} # Limita la lunghezza per evitare errori API
                    ---
                    """
                    evaluation_response_text = gemini_client.generate_content(evaluation_prompt)

                    # Estrai JSON dalla risposta
                    try:
                        json_start = evaluation_response_text.find('{')
                        json_end = evaluation_response_text.rfind('}') + 1
                        if json_start != -1 and json_end != 0:
                            json_str = evaluation_response_text[json_start:json_end]
                            evaluation_result = json.loads(json_str)
                            logger.info(f"Valutazione per '{topic_data['name']}': Score={evaluation_result.get('score')}, Justification='{evaluation_result.get('justification')}'")
                            # Qui potresti salvare evaluation_result nel DB o passarlo al template
                        else:
                             logger.warning(f"Nessun JSON trovato nella risposta di valutazione per '{topic_data['name']}'. Risposta: {evaluation_response_text}")
                    except json.JSONDecodeError as json_err:
                        logger.error(f"Errore parsing JSON valutazione per '{topic_data['name']}': {json_err}. Risposta: {evaluation_response_text}")
                    except Exception as parse_err:
                         logger.error(f"Errore imprevisto parsing valutazione per '{topic_data['name']}': {parse_err}. Risposta: {evaluation_response_text}")

                except Exception as eval_err:
                    logger.error(f"Errore durante la chiamata LLM di valutazione per '{topic_data['name']}': {str(eval_err)}")
                # --- FINE VALUTAZIONE LLM ---


                # --- Salvataggio Nota nel DB ---
                if db_topic_obj:
                    # ... (codice esistente per salvare/aggiornare la nota nel DB) ...

                    # Commit dopo ogni nota per salvare il progresso
                    db.session.commit()

                    # Aggiungi alla lista delle note generate in questa run
                    generated_notes[topic_id] = {
                        'name': topic_data['name'],
                        'content': formatted_content, # Inizialmente senza hyperlink
                        'format': output_format
                        # Potresti aggiungere qui i dati di valutazione se vuoi passarli al template
                        # 'evaluation': evaluation_result
                    }
                    successfully_processed_count += 1
                else:
                    # ... (codice esistente per warning) ...

            except Exception as e:
                # ... (codice esistente per gestione errori argomento) ...

        # --- FINE CICLO ---
        logger.info(f"Ciclo di generazione completato. Argomenti processati con successo: {successfully_processed_count}/{len(topics_dict)}")

        # --- AGGIUNTA HYPERLINK (dopo che tutte le note base sono state generate) ---
        # ... (codice esistente per aggiungere hyperlink) ...

        # Aggiorna la sessione con tutte le note processate
        # ... (codice esistente per aggiornare session_data) ...

        # Messaggi finali per l'utente
        # ... (codice esistente per flash messages) ...

        return render_template(
            'results.html',
            topics=topics_dict,
            granularity=session_data.get('current_granularity', 50),
            notes=generated_notes, # Mostra le note generate
            selected_format=output_format
        )

    except Exception as e:
        # ... (codice esistente per gestione errori generali) ...

# ... (resto del codice app.py) ...
```

Questo esempio aggiunge la logica di valutazione all'interno del ciclo di generazione delle note e registra i risultati. Per una soluzione pi√π robusta, potresti voler creare una funzione o classe dedicata per la valutazione e gestire meglio i potenziali errori API o di parsing JSON.